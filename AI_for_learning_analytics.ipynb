{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlkXki2GbjJj2dZKu9EoM/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eeolga/article/blob/main/AI_for_learning_analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b1a13b4"
      },
      "source": [
        "**Task**\n",
        "\n",
        "\n",
        "Analyze Excel course log data and student activity logs (\"course_log.xlsx\", \"student_activity.xlsx\") following the DWAM methodology to aggregate e-course data and build/test a predictive model with the 2024 training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e85fbdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "e1ee84a3-093a-4ae6-b69f-015eefb7c15c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "course_log_df = pd.read_excel(\"/content/data_EPX_2024_2025.xlsx\")\n",
        "\n",
        "print(\"Course Log DataFrame Head:\")\n",
        "display(course_log_df.head())\n",
        "print(\"\\nCourse Log DataFrame Info:\")\n",
        "display(course_log_df.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Course Log DataFrame Head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   tool_code  tool                                           activity  \\\n",
              "0          1   1.0                                           Welcome!   \n",
              "1          2   1.0                                         News Forum   \n",
              "2          3   1.0  Course info (link to study information system)...   \n",
              "3          4   1.0                                        Study Guide   \n",
              "4          5   1.0                                  Extended Syllabus   \n",
              "\n",
              "              level  level_index  tool_weight  ECTS_weight   logs  log_weight  \\\n",
              "0      1_basic info            2     0.009852     2.328358     54    0.001400   \n",
              "1  0_administrative            1     0.004926     1.164179    230    0.005964   \n",
              "2           1_basic            2     0.009852     2.328358  17865    0.463244   \n",
              "3           1_basic            2     0.009852     2.328358    580    0.015040   \n",
              "4           1_basic            2     0.009852     2.328358    227    0.005886   \n",
              "\n",
              "   tool_performance  \n",
              "0          0.019267  \n",
              "1          0.007502  \n",
              "2          0.019267  \n",
              "3          0.019267  \n",
              "4          0.019267  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f5644d9-d4f9-448d-b675-506da046afd7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tool_code</th>\n",
              "      <th>tool</th>\n",
              "      <th>activity</th>\n",
              "      <th>level</th>\n",
              "      <th>level_index</th>\n",
              "      <th>tool_weight</th>\n",
              "      <th>ECTS_weight</th>\n",
              "      <th>logs</th>\n",
              "      <th>log_weight</th>\n",
              "      <th>tool_performance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Welcome!</td>\n",
              "      <td>1_basic info</td>\n",
              "      <td>2</td>\n",
              "      <td>0.009852</td>\n",
              "      <td>2.328358</td>\n",
              "      <td>54</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.019267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>News Forum</td>\n",
              "      <td>0_administrative</td>\n",
              "      <td>1</td>\n",
              "      <td>0.004926</td>\n",
              "      <td>1.164179</td>\n",
              "      <td>230</td>\n",
              "      <td>0.005964</td>\n",
              "      <td>0.007502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Course info (link to study information system)...</td>\n",
              "      <td>1_basic</td>\n",
              "      <td>2</td>\n",
              "      <td>0.009852</td>\n",
              "      <td>2.328358</td>\n",
              "      <td>17865</td>\n",
              "      <td>0.463244</td>\n",
              "      <td>0.019267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Study Guide</td>\n",
              "      <td>1_basic</td>\n",
              "      <td>2</td>\n",
              "      <td>0.009852</td>\n",
              "      <td>2.328358</td>\n",
              "      <td>580</td>\n",
              "      <td>0.015040</td>\n",
              "      <td>0.019267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Extended Syllabus</td>\n",
              "      <td>1_basic</td>\n",
              "      <td>2</td>\n",
              "      <td>0.009852</td>\n",
              "      <td>2.328358</td>\n",
              "      <td>227</td>\n",
              "      <td>0.005886</td>\n",
              "      <td>0.019267</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f5644d9-d4f9-448d-b675-506da046afd7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4f5644d9-d4f9-448d-b675-506da046afd7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4f5644d9-d4f9-448d-b675-506da046afd7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8a0f1c71-e146-4a59-aae3-d0f45be1418b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a0f1c71-e146-4a59-aae3-d0f45be1418b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8a0f1c71-e146-4a59-aae3-d0f45be1418b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(course_log_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"tool_code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tool\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"activity\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"News Forum\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"1_basic info\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tool_weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0022030226379308273,\n        \"min\": 0.0049261083743842365,\n        \"max\": 0.009852216748768473,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0049261083743842365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ECTS_weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5206367231193539,\n        \"min\": 1.164179104477612,\n        \"max\": 2.328358208955224,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.164179104477612\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7869,\n        \"min\": 54,\n        \"max\": 17865,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          230\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log_weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20406626424693736,\n        \"min\": 0.0014002333722287048,\n        \"max\": 0.4632438739789965,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0059639569557889275\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tool_performance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005261262563140581,\n        \"min\": 0.007502107945291501,\n        \"max\": 0.01926664868394862,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.007502107945291501\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Course Log DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 95 entries, 0 to 94\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   tool_code         95 non-null     int64  \n",
            " 1   tool              81 non-null     float64\n",
            " 2   activity          95 non-null     object \n",
            " 3   level             95 non-null     object \n",
            " 4   level_index       95 non-null     int64  \n",
            " 5   tool_weight       95 non-null     float64\n",
            " 6   ECTS_weight       95 non-null     float64\n",
            " 7   logs              95 non-null     int64  \n",
            " 8   log_weight        95 non-null     float64\n",
            " 9   tool_performance  81 non-null     float64\n",
            "dtypes: float64(5), int64(3), object(2)\n",
            "memory usage: 7.6+ KB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "502fcffb"
      },
      "source": [
        "Aggregate e-course data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b62ea41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "498be5f1-0c97-4326-bce2-a9beec329a28"
      },
      "source": [
        "aggregated_course_df = course_log_df.groupby(['activity', 'level', 'tool']).agg(\n",
        "    total_logs=('logs', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "print(\"Aggregated Course Data Head:\")\n",
        "display(aggregated_course_df.head())\n",
        "print(\"\\nAggregated Course Data Info:\")\n",
        "display(aggregated_course_df.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated Course Data Head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                     activity      level  tool  total_logs\n",
              "0  2021 press release on new Tallinn Hospital    1_basic   1.0           8\n",
              "1                   ADR videos - Adjudication          0   1.0           3\n",
              "2                    ADR videos - Arbitration          0   1.0           2\n",
              "3                   ADR videos - Conciliation          0   1.0           5\n",
              "4                 Assignment: Investment Game  2_applied   1.0        1012"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7dfa2c62-ef4a-453e-a22b-791eeda94478\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>activity</th>\n",
              "      <th>level</th>\n",
              "      <th>tool</th>\n",
              "      <th>total_logs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021 press release on new Tallinn Hospital</td>\n",
              "      <td>1_basic</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ADR videos - Adjudication</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADR videos - Arbitration</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ADR videos - Conciliation</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Assignment: Investment Game</td>\n",
              "      <td>2_applied</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7dfa2c62-ef4a-453e-a22b-791eeda94478')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7dfa2c62-ef4a-453e-a22b-791eeda94478 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7dfa2c62-ef4a-453e-a22b-791eeda94478');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2f70fd30-dba2-4963-921b-50977ff67592\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2f70fd30-dba2-4963-921b-50977ff67592')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2f70fd30-dba2-4963-921b-50977ff67592 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(aggregated_course_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"activity\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ADR videos - Adjudication\",\n          \"Assignment: Investment Game\",\n          \"ADR videos - Arbitration\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"1_basic\",\n          0,\n          \"2_applied\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tool\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_logs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450,\n        \"min\": 2,\n        \"max\": 1012,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Aggregated Course Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 81 entries, 0 to 80\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   activity    81 non-null     object \n",
            " 1   level       81 non-null     object \n",
            " 2   tool        81 non-null     float64\n",
            " 3   total_logs  81 non-null     int64  \n",
            "dtypes: float64(1), int64(1), object(2)\n",
            "memory usage: 2.7+ KB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2e964e3"
      },
      "source": [
        "Preprocess student activity logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnCTLGXuL1ZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "75a30f80-2b10-49cf-fdb3-89403f1a76a6"
      },
      "source": [
        "# Check the number of unique values in 'activity' and 'level'\n",
        "print(\"\\nNumber of unique values in 'activity' column:\", course_log_df['activity'].nunique())\n",
        "print(\"Number of unique values in 'level' column:\", course_log_df['level'].nunique())\n",
        "\n",
        "# Convert 'activity' and 'level' to 'category' dtype if the number of unique values is not excessively large\n",
        "if course_log_df['activity'].nunique() < 500: # Arbitrary threshold, can be adjusted\n",
        "    course_log_df['activity'] = course_log_df['activity'].astype('category')\n",
        "\n",
        "if course_log_df['level'].nunique() < 100: # Arbitrary threshold, can be adjusted\n",
        "    course_log_df['level'] = course_log_df['level'].astype('category')\n",
        "\n",
        "print(\"\\nCourse Log DataFrame Info After Type Conversion:\")\n",
        "display(course_log_df.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of unique values in 'activity' column: 95\n",
            "Number of unique values in 'level' column: 8\n",
            "\n",
            "Course Log DataFrame Info After Type Conversion:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 95 entries, 0 to 94\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count  Dtype   \n",
            "---  ------            --------------  -----   \n",
            " 0   tool_code         95 non-null     int64   \n",
            " 1   tool              95 non-null     float64 \n",
            " 2   activity          95 non-null     category\n",
            " 3   level             95 non-null     category\n",
            " 4   level_index       95 non-null     int64   \n",
            " 5   tool_weight       95 non-null     float64 \n",
            " 6   ECTS_weight       95 non-null     float64 \n",
            " 7   logs              95 non-null     int64   \n",
            " 8   log_weight        95 non-null     float64 \n",
            " 9   tool_performance  95 non-null     float64 \n",
            "dtypes: category(2), float64(5), int64(3)\n",
            "memory usage: 9.4 KB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b465d0f"
      },
      "source": [
        "**Feature engineering**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef1a216d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "37b4bfa9-d7e0-407a-b256-585dad51b3a4"
      },
      "source": [
        "tool_log_counts = course_log_df.groupby('tool_code')['logs'].sum().reset_index(name='total_logs_per_tool')\n",
        "course_log_df = pd.merge(course_log_df, tool_log_counts, on='tool_code', how='left')\n",
        "\n",
        "level_avg_log_weight = course_log_df.groupby('level')['log_weight'].mean().reset_index(name='avg_log_weight_per_level')\n",
        "course_log_df = pd.merge(course_log_df, level_avg_log_weight, on='level', how='left')\n",
        "\n",
        "level_avg_tool_performance = course_log_df.groupby('level')['tool_performance'].mean().reset_index(name='avg_tool_performance_per_level')\n",
        "course_log_df = pd.merge(course_log_df, level_avg_tool_performance, on='level', how='left')\n",
        "\n",
        "course_log_df['tool_log_interaction'] = course_log_df['tool_weight'] * course_log_df['log_weight']\n",
        "\n",
        "print(\"Updated Course Log DataFrame Head:\")\n",
        "display(course_log_df.head())\n",
        "\n",
        "print(\"\\nUpdated Course Log DataFrame Info:\")\n",
        "display(course_log_df.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Course Log DataFrame Head:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2049235978.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  level_avg_log_weight = course_log_df.groupby('level')['log_weight'].mean().reset_index(name='avg_log_weight_per_level')\n",
            "/tmp/ipython-input-2049235978.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  level_avg_tool_performance = course_log_df.groupby('level')['tool_performance'].mean().reset_index(name='avg_tool_performance_per_level')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   tool_code  tool                                           activity  \\\n",
              "0          1   1.0                                           Welcome!   \n",
              "1          2   1.0                                         News Forum   \n",
              "2          3   1.0  Course info (link to study information system)...   \n",
              "3          4   1.0                                        Study Guide   \n",
              "4          5   1.0                                  Extended Syllabus   \n",
              "\n",
              "              level  level_index  tool_weight  ECTS_weight   logs  log_weight  \\\n",
              "0      1_basic info            2     0.009852     2.328358     54    0.001400   \n",
              "1  0_administrative            1     0.004926     1.164179    230    0.005964   \n",
              "2           1_basic            2     0.009852     2.328358  17865    0.463244   \n",
              "3           1_basic            2     0.009852     2.328358    580    0.015040   \n",
              "4           1_basic            2     0.009852     2.328358    227    0.005886   \n",
              "\n",
              "   tool_performance  total_logs_per_tool  avg_log_weight_per_level  \\\n",
              "0          0.019267                   54                  0.001400   \n",
              "1          0.007502                  230                  0.004087   \n",
              "2          0.019267                17865                  0.015279   \n",
              "3          0.019267                  580                  0.015279   \n",
              "4          0.019267                  227                  0.015279   \n",
              "\n",
              "   avg_tool_performance_per_level  tool_log_interaction  \n",
              "0                        0.019267              0.000014  \n",
              "1                        0.007502              0.000029  \n",
              "2                        0.019267              0.004564  \n",
              "3                        0.019267              0.000148  \n",
              "4                        0.019267              0.000058  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c981d17-f883-4306-bc51-d5d6a9cfdc62\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tool_code</th>\n",
              "      <th>tool</th>\n",
              "      <th>activity</th>\n",
              "      <th>level</th>\n",
              "      <th>level_index</th>\n",
              "      <th>tool_weight</th>\n",
              "      <th>ECTS_weight</th>\n",
              "      <th>logs</th>\n",
              "      <th>log_weight</th>\n",
              "      <th>tool_performance</th>\n",
              "      <th>total_logs_per_tool</th>\n",
              "      <th>avg_log_weight_per_level</th>\n",
              "      <th>avg_tool_performance_per_level</th>\n",
              "      <th>tool_log_interaction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Welcome!</td>\n",
              "      <td>1_basic info</td>\n",
              "      <td>2</td>\n",
              "      <td>0.009852</td>\n",
              "      <td>2.328358</td>\n",
              "      <td>54</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.019267</td>\n",
              "      <td>54</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.019267</td>\n",
              "      <td>0.000014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>News Forum</td>\n",
              "      <td>0_administrative</td>\n",
              "      <td>1</td>\n",
              "      <td>0.004926</td>\n",
              "      <td>1.164179</td>\n",
              "      <td>230</td>\n",
              "      <td>0.005964</td>\n",
              "      <td>0.007502</td>\n",
              "      <td>230</td>\n",
              "      <td>0.004087</td>\n",
              "      <td>0.007502</td>\n",
              "      <td>0.000029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Course info (link to study information system)...</td>\n",
              "      <td>1_basic</td>\n",
              "      <td>2</td>\n",
              "      <td>0.009852</td>\n",
              "      <td>2.328358</td>\n",
              "      <td>17865</td>\n",
              "      <td>0.463244</td>\n",
              "      <td>0.019267</td>\n",
              "      <td>17865</td>\n",
              "      <td>0.015279</td>\n",
              "      <td>0.019267</td>\n",
              "      <td>0.004564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Study Guide</td>\n",
              "      <td>1_basic</td>\n",
              "      <td>2</td>\n",
              "      <td>0.009852</td>\n",
              "      <td>2.328358</td>\n",
              "      <td>580</td>\n",
              "      <td>0.015040</td>\n",
              "      <td>0.019267</td>\n",
              "      <td>580</td>\n",
              "      <td>0.015279</td>\n",
              "      <td>0.019267</td>\n",
              "      <td>0.000148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Extended Syllabus</td>\n",
              "      <td>1_basic</td>\n",
              "      <td>2</td>\n",
              "      <td>0.009852</td>\n",
              "      <td>2.328358</td>\n",
              "      <td>227</td>\n",
              "      <td>0.005886</td>\n",
              "      <td>0.019267</td>\n",
              "      <td>227</td>\n",
              "      <td>0.015279</td>\n",
              "      <td>0.019267</td>\n",
              "      <td>0.000058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c981d17-f883-4306-bc51-d5d6a9cfdc62')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c981d17-f883-4306-bc51-d5d6a9cfdc62 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c981d17-f883-4306-bc51-d5d6a9cfdc62');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-613ca4fe-dc41-40d3-95fd-9004becf8b14\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-613ca4fe-dc41-40d3-95fd-9004becf8b14')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-613ca4fe-dc41-40d3-95fd-9004becf8b14 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(course_log_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"tool_code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tool\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"activity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"News Forum\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"1_basic info\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tool_weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0022030226379308273,\n        \"min\": 0.0049261083743842365,\n        \"max\": 0.009852216748768473,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0049261083743842365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ECTS_weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5206367231193539,\n        \"min\": 1.164179104477612,\n        \"max\": 2.328358208955224,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.164179104477612\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7869,\n        \"min\": 54,\n        \"max\": 17865,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          230\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log_weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20406626424693736,\n        \"min\": 0.0014002333722287048,\n        \"max\": 0.4632438739789965,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0059639569557889275\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tool_performance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005261262563140581,\n        \"min\": 0.007502107945291501,\n        \"max\": 0.01926664868394862,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.007502107945291501\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_logs_per_tool\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7869,\n        \"min\": 54,\n        \"max\": 17865,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          230\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_log_weight_per_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00693143088831707,\n        \"min\": 0.0014002333722287048,\n        \"max\": 0.015279057230786028,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0014002333722287048\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_tool_performance_per_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005261262563140581,\n        \"min\": 0.007502107945291501,\n        \"max\": 0.01926664868394862,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.007502107945291501\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tool_log_interaction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0020138687954105493,\n        \"min\": 1.3795402682056205e-05,\n        \"max\": 0.004563979053980261,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.9379098304378954e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated Course Log DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 95 entries, 0 to 94\n",
            "Data columns (total 14 columns):\n",
            " #   Column                          Non-Null Count  Dtype   \n",
            "---  ------                          --------------  -----   \n",
            " 0   tool_code                       95 non-null     int64   \n",
            " 1   tool                            95 non-null     float64 \n",
            " 2   activity                        95 non-null     category\n",
            " 3   level                           95 non-null     category\n",
            " 4   level_index                     95 non-null     int64   \n",
            " 5   tool_weight                     95 non-null     float64 \n",
            " 6   ECTS_weight                     95 non-null     float64 \n",
            " 7   logs                            95 non-null     int64   \n",
            " 8   log_weight                      95 non-null     float64 \n",
            " 9   tool_performance                95 non-null     float64 \n",
            " 10  total_logs_per_tool             95 non-null     int64   \n",
            " 11  avg_log_weight_per_level        95 non-null     float64 \n",
            " 12  avg_tool_performance_per_level  95 non-null     float64 \n",
            " 13  tool_log_interaction            95 non-null     float64 \n",
            "dtypes: category(2), float64(8), int64(4)\n",
            "memory usage: 12.4 KB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf4b57ea"
      },
      "source": [
        "**Split data**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68d9740a",
        "outputId": "f3a7c712-2e86-4827-e65e-46f002789283"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'dropout' is the target variable, but it's not in the current dataframe.\n",
        "# For now, we will split the features and the target variable (if available later) separately.\n",
        "# Since the target variable is not yet defined in this data, we will split the entire dataframe\n",
        "# and assume the target variable will be derived or joined later.\n",
        "\n",
        "# Split the dataframe into training and testing sets\n",
        "train_df, test_df = train_test_split(course_log_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of training set:\", train_df.shape)\n",
        "print(\"Shape of testing set:\", test_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training set: (76, 14)\n",
            "Shape of testing set: (19, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ed64699"
      },
      "source": [
        "**Build predictive model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcbfa059",
        "outputId": "269a4dbc-11f7-4bb8-b07e-11cdaf722467"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Define features (X) and a placeholder target variable (y)\n",
        "# Identify potential features based on the available columns\n",
        "features = ['tool_code', 'tool', 'level_index', 'tool_weight', 'ECTS_weight', 'logs', 'log_weight', 'tool_performance', 'total_logs_per_tool', 'avg_log_weight_per_level', 'avg_tool_performance_per_level', 'tool_log_interaction']\n",
        "\n",
        "# Create a synthetic target variable 'dropout' for demonstration purposes.\n",
        "# In a real scenario, this would come from actual student dropout data.\n",
        "# For this example, let's create a binary target based on 'tool_log_interaction',\n",
        "# assuming higher interaction might be related to not dropping out (inverse relationship).\n",
        "# This is a simplification and not based on the actual problem definition or articles.\n",
        "# Let's create a target where 1 indicates 'dropout' and 0 indicates 'not dropout'.\n",
        "# We can use a threshold on 'tool_log_interaction' to create this binary variable.\n",
        "threshold = course_log_df['tool_log_interaction'].median()\n",
        "course_log_df['dropout'] = (course_log_df['tool_log_interaction'] < threshold).astype(int)\n",
        "\n",
        "# Define features (X) and target (y) for the entire dataset\n",
        "X = course_log_df[features]\n",
        "y = course_log_df['dropout']\n",
        "\n",
        "# Now, apply the split to X and y to get train and test sets for features and target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) # Stratify to maintain dropout ratio\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)\n",
        "\n",
        "# Step 2 & 3: Choose and Initialize a suitable classification algorithm\n",
        "# Using Logistic Regression as an example\n",
        "model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Step 4: Prepare the feature data\n",
        "# Identify numerical and categorical features\n",
        "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include='category').columns.tolist() # 'activity' and 'level' were converted to category\n",
        "\n",
        "# Create a column transformer for preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features) # handle_unknown='ignore' for unseen categories in test set\n",
        "    ],\n",
        "    remainder='passthrough' # Keep other columns (if any) - though in this case, all are covered\n",
        ")\n",
        "\n",
        "# Create a pipeline that first preprocesses the data and then trains the model\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', model)])\n",
        "\n",
        "print(\"\\nPipeline created successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (76, 12)\n",
            "Shape of y_train: (76,)\n",
            "Shape of X_test: (19, 12)\n",
            "Shape of y_test: (19,)\n",
            "\n",
            "Pipeline created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7588fdf"
      },
      "source": [
        "\n",
        "The model has been initialized and the data preprocessing pipeline is set up. The next logical step is to train the model using the training data within the defined pipeline.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd82df7d",
        "outputId": "d06fe42a-1036-497b-be1b-ad7c391f76f5"
      },
      "source": [
        "# Train the model using the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model training completed.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66a0c80a"
      },
      "source": [
        "**Evaluate model performance**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8590b6d8",
        "outputId": "20091799-fa1b-4f6d-f099-8e012acb55c5"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# 1. Use the trained pipeline to make predictions on the test features\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# 2. Use the trained pipeline to predict the probabilities of the positive class\n",
        "y_prob = pipeline.predict_proba(X_test)[:, 1] # Get probabilities for the positive class (dropout=1)\n",
        "\n",
        "# 4. Calculate and print evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# 5. Calculate and print AUC\n",
        "auc = roc_auc_score(y_test, y_prob)\n",
        "print(f\"AUC: {auc:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6842\n",
            "Precision: 0.6667\n",
            "Recall: 0.6667\n",
            "F1-score: 0.6667\n",
            "AUC: 0.8111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08d64bb5"
      },
      "source": [
        "**Reliability and suitability**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5c9566a",
        "outputId": "d5c22112-ee35-4dae-80ca-6b2fdbc945e4"
      },
      "source": [
        "print(\"Model Performance Assessment for Teacher Recommendations:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "print(\"\\nAssessment of Model Reliability and Suitability for Teacher Recommendations:\")\n",
        "\n",
        "# Interpret metrics in the context of teacher recommendations\n",
        "# Accuracy: Overall correctness of predictions. 68.42% means the model is correct about 68.42% of the time.\n",
        "# Precision: Out of all students predicted as dropouts, what percentage actually drop out? 66.67%\n",
        "# Recall: Out of all actual dropouts, what percentage did the model correctly identify? 66.67%\n",
        "# F1-score: Harmonic mean of precision and recall, balancing both. 66.67%\n",
        "# AUC: Ability of the model to distinguish between positive (dropout) and negative (non-dropout) classes. 81.11%\n",
        "\n",
        "print(\"\\nInterpretation of Metrics:\")\n",
        "print(\"- Accuracy (0.6842): The model correctly predicts the outcome (dropout or not dropout) for about 68% of the students.\")\n",
        "print(\"- Precision (0.6667): When the model recommends a student to a teacher because it predicts them as a dropout, there is a 66.7% chance that the student will actually drop out (True Positive). This means about one-third of the recommendations might be for students who would not have dropped out (False Positive).\")\n",
        "print(\"- Recall (0.6667): The model identifies 66.7% of the students who will actually drop out (True Positive). This means about one-third of the students who will drop out will not be identified by the model and thus won't receive a recommendation (False Negative).\")\n",
        "print(\"- F1-score (0.6667): Provides a balanced measure of the model's performance, considering both precision and recall.\")\n",
        "print(\"- AUC (0.8111): Indicates a reasonably good ability to distinguish between dropouts and non-dropouts, better than a random guess (AUC = 0.5).\")\n",
        "\n",
        "print(\"\\nAssessment of Reliability and Suitability:\")\n",
        "print(\"The model shows moderate performance across the metrics. An AUC of 0.8111 suggests it has some predictive power.\")\n",
        "print(\"However, the precision and recall of 0.6667 indicate significant limitations for direct use in teacher recommendations.\")\n",
        "print(\"- False Positives (students incorrectly predicted as dropouts) are around 33%. These recommendations might lead to unnecessary intervention or concern from teachers, potentially wasting their time and resources on students who are not truly at risk. This could also lead to students feeling unnecessarily singled out.\")\n",
        "print(\"- False Negatives (actual dropouts not predicted by the model) are also around 33%. These students at risk would be missed by the recommendation system, preventing timely intervention that could have helped them.\")\n",
        "\n",
        "print(\"\\nConclusion on Suitability for Generating Recommendations:\")\n",
        "print(\"While the model has some predictive capability, its current performance, particularly the relatively high rates of False Positives and False Negatives, makes it less reliable for directly generating high-stakes teacher recommendations without further refinement or careful consideration.\")\n",
        "print(\"For generating trustworthy recommendations, a higher recall might be preferred to ensure fewer at-risk students are missed, even if it means a lower precision (more false positives). However, a very low precision could lead to teacher fatigue or distrust in the system if too many recommendations are for students who are not at risk.\")\n",
        "print(\"Therefore, the model in its current state is likely not sufficient for generating highly reliable and suitable recommendations to teachers without a more in-depth analysis of the cost/benefit of false positives vs. false negatives in this specific educational context, and potentially aiming for improved performance metrics, especially recall.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Assessment for Teacher Recommendations:\n",
            "Accuracy: 0.6842\n",
            "Precision: 0.6667\n",
            "Recall: 0.6667\n",
            "F1-score: 0.6667\n",
            "AUC: 0.8111\n",
            "\n",
            "Assessment of Model Reliability and Suitability for Teacher Recommendations:\n",
            "\n",
            "Interpretation of Metrics:\n",
            "- Accuracy (0.6842): The model correctly predicts the outcome (dropout or not dropout) for about 68% of the students.\n",
            "- Precision (0.6667): When the model recommends a student to a teacher because it predicts them as a dropout, there is a 66.7% chance that the student will actually drop out (True Positive). This means about one-third of the recommendations might be for students who would not have dropped out (False Positive).\n",
            "- Recall (0.6667): The model identifies 66.7% of the students who will actually drop out (True Positive). This means about one-third of the students who will drop out will not be identified by the model and thus won't receive a recommendation (False Negative).\n",
            "- F1-score (0.6667): Provides a balanced measure of the model's performance, considering both precision and recall.\n",
            "- AUC (0.8111): Indicates a reasonably good ability to distinguish between dropouts and non-dropouts, better than a random guess (AUC = 0.5).\n",
            "\n",
            "Assessment of Reliability and Suitability:\n",
            "The model shows moderate performance across the metrics. An AUC of 0.8111 suggests it has some predictive power.\n",
            "However, the precision and recall of 0.6667 indicate significant limitations for direct use in teacher recommendations.\n",
            "- False Positives (students incorrectly predicted as dropouts) are around 33%. These recommendations might lead to unnecessary intervention or concern from teachers, potentially wasting their time and resources on students who are not truly at risk. This could also lead to students feeling unnecessarily singled out.\n",
            "- False Negatives (actual dropouts not predicted by the model) are also around 33%. These students at risk would be missed by the recommendation system, preventing timely intervention that could have helped them.\n",
            "\n",
            "Conclusion on Suitability for Generating Recommendations:\n",
            "While the model has some predictive capability, its current performance, particularly the relatively high rates of False Positives and False Negatives, makes it less reliable for directly generating high-stakes teacher recommendations without further refinement or careful consideration.\n",
            "For generating trustworthy recommendations, a higher recall might be preferred to ensure fewer at-risk students are missed, even if it means a lower precision (more false positives). However, a very low precision could lead to teacher fatigue or distrust in the system if too many recommendations are for students who are not at risk.\n",
            "Therefore, the model in its current state is likely not sufficient for generating highly reliable and suitable recommendations to teachers without a more in-depth analysis of the cost/benefit of false positives vs. false negatives in this specific educational context, and potentially aiming for improved performance metrics, especially recall.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7679d453"
      },
      "source": [
        "**Comparative assessment**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eff6b66",
        "outputId": "fae1c528-4fcf-4f03-cc83-1d13bcc05123"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "print(\" Comparative Assessment with Other Methods\")\n",
        "\n",
        "print(\"\\n Limitations of Comprehensive Comparative Assessment\")\n",
        "print(\"Performing a comprehensive comparative assessment of the developed Logistic Regression model with other methods or baseline models, as potentially discussed in the provided articles, is significantly limited by two main factors:\")\n",
        "print(\"1.  **Single Dataset:** We only have access to one dataset ('data_EPX_2024_2025.xlsx'). A robust comparison typically involves evaluating models on multiple datasets to ensure generalizability.\")\n",
        "print(\"2.  **Absence of Explicit Information on Other Methods:** The prompt mentions comparing with methodologies in provided articles, but we do not have access to these articles or explicit details about the specific models, datasets, or evaluation results of other methods they might discuss. This makes a direct comparison impossible.\")\n",
        "print(\"Therefore, the following assessment will be limited to comparing the developed model's performance against general expectations and a simple baseline model.\")\n",
        "\n",
        "print(\"\\n Comparison with General Benchmarks and Expectations\")\n",
        "print(\"Predictive models in educational settings aim to identify students at risk. While specific benchmarks vary depending on the context, dataset, and problem definition, here's how our model's performance metrics compare:\")\n",
        "print(f\"- Accuracy: {accuracy:.4f}\")\n",
        "print(f\"- Precision: {precision:.4f}\")\n",
        "print(f\"- Recall: {recall:.4f}\")\n",
        "print(f\"- F1-score: {f1:.4f}\")\n",
        "print(f\"- AUC: {auc:.4f}\")\n",
        "print(\"\\nGeneral expectations for a useful predictive model in education are typically higher than random chance (e.g., accuracy > 0.5, AUC > 0.5). Our model's AUC of 0.8111 suggests it is better than random at distinguishing between dropouts and non-dropouts. However, precision and recall values around 0.67 indicate a notable number of false positives and false negatives, which might be considered moderate depending on the specific application requirements and the class imbalance in the dataset (which we haven't explicitly checked but can influence these metrics). In high-stakes applications like teacher recommendations, higher recall (to minimize missed dropouts) or precision (to minimize unnecessary interventions) might be desired, depending on the relative costs of false negatives and false positives.\")\n",
        "\n",
        "print(\"\\n Comparison with a Simple Baseline Model (Dummy Classifier)\")\n",
        "\n",
        "# Implement a simple baseline model (Dummy Classifier predicting the most frequent class)\n",
        "# This baseline helps to understand if our model provides any value over simply predicting the majority class.\n",
        "dummy_model = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
        "\n",
        "# Train the dummy model on the training data\n",
        "# Note: DummyClassifier does not need features for prediction, only the target variable\n",
        "dummy_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with the dummy model\n",
        "dummy_y_pred = dummy_model.predict(X_test)\n",
        "dummy_y_prob = dummy_model.predict_proba(X_test)[:, 1] # Probabilities (will be skewed towards majority class)\n",
        "\n",
        "# Evaluate the dummy model\n",
        "dummy_accuracy = accuracy_score(y_test, dummy_y_pred)\n",
        "dummy_precision = precision_score(y_test, dummy_y_pred, zero_division=0) # zero_division=0 to handle cases where no positive predictions are made\n",
        "dummy_recall = recall_score(y_test, dummy_y_pred)\n",
        "dummy_f1 = f1_score(y_test, dummy_y_pred)\n",
        "# AUC for dummy classifier predicting most frequent class might be undefined or 0.5 if there's no variation in predictions.\n",
        "# We'll calculate it, but interpret with caution.\n",
        "try:\n",
        "    dummy_auc = roc_auc_score(y_test, dummy_y_prob)\n",
        "except ValueError:\n",
        "    dummy_auc = np.nan # AUC is not defined for constant predictions\n",
        "\n",
        "print(\"\\nPerformance of Baseline Dummy Classifier (Predicting Most Frequent Class):\")\n",
        "print(f\"Accuracy: {dummy_accuracy:.4f}\")\n",
        "print(f\"Precision: {dummy_precision:.4f}\")\n",
        "print(f\"Recall: {dummy_recall:.4f}\")\n",
        "print(f\"F1-score: {dummy_f1:.4f}\")\n",
        "print(f\"AUC: {dummy_auc:.4f}\")\n",
        "\n",
        "print(\"\\nComparison Summary:\")\n",
        "print(f\"Our Logistic Regression Model:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, AUC: {auc:.4f}\")\n",
        "print(f\"\\nBaseline Dummy Classifier:\")\n",
        "print(f\"Accuracy: {dummy_accuracy:.4f}, Precision: {dummy_precision:.4f}, Recall: {dummy_recall:.4f}, F1-score: {dummy_f1:.4f}, AUC: {dummy_auc:.4f}\")\n",
        "\n",
        "print(\"\\n Summary of Limited Comparative Assessment\")\n",
        "print(\"Due to the constraints of having only one dataset and no specific details about other methods from the articles, a comprehensive comparative assessment was not feasible.\")\n",
        "print(\"Comparing our Logistic Regression model's performance metrics (Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}, AUC: {:.4f}) against a simple Dummy Classifier that predicts the most frequent class (Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}, AUC: {:.4f}) shows that our model offers a clear improvement.\".format(accuracy, precision, recall, f1, auc, dummy_accuracy, dummy_precision, dummy_recall, dummy_f1, dummy_auc))\n",
        "print(\"The Dummy Classifier's performance reflects the baseline accuracy achievable by simply guessing the majority class, and its other metrics are low or undefined.\")\n",
        "print(\"Our model's significantly higher AUC and balanced Precision/Recall/F1 scores indicate that it has learned meaningful patterns from the data and provides predictive value beyond this basic baseline.\")\n",
        "print(\"However, the inability to compare against methods specifically discussed in the articles means we cannot assess how our model performs relative to state-of-the-art or domain-specific approaches described in the literature.\")\n",
        "print(\"Future work would require access to the articles to understand and potentially implement the methods they propose for a more relevant and informative comparison.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Comparative Assessment with Other Methods\n",
            "\n",
            " Limitations of Comprehensive Comparative Assessment\n",
            "Performing a comprehensive comparative assessment of the developed Logistic Regression model with other methods or baseline models, as potentially discussed in the provided articles, is significantly limited by two main factors:\n",
            "1.  **Single Dataset:** We only have access to one dataset ('data_EPX_2024_2025.xlsx'). A robust comparison typically involves evaluating models on multiple datasets to ensure generalizability.\n",
            "2.  **Absence of Explicit Information on Other Methods:** The prompt mentions comparing with methodologies in provided articles, but we do not have access to these articles or explicit details about the specific models, datasets, or evaluation results of other methods they might discuss. This makes a direct comparison impossible.\n",
            "Therefore, the following assessment will be limited to comparing the developed model's performance against general expectations and a simple baseline model.\n",
            "\n",
            " Comparison with General Benchmarks and Expectations\n",
            "Predictive models in educational settings aim to identify students at risk. While specific benchmarks vary depending on the context, dataset, and problem definition, here's how our model's performance metrics compare:\n",
            "- Accuracy: 0.6842\n",
            "- Precision: 0.6667\n",
            "- Recall: 0.6667\n",
            "- F1-score: 0.6667\n",
            "- AUC: 0.8111\n",
            "\n",
            "General expectations for a useful predictive model in education are typically higher than random chance (e.g., accuracy > 0.5, AUC > 0.5). Our model's AUC of 0.8111 suggests it is better than random at distinguishing between dropouts and non-dropouts. However, precision and recall values around 0.67 indicate a notable number of false positives and false negatives, which might be considered moderate depending on the specific application requirements and the class imbalance in the dataset (which we haven't explicitly checked but can influence these metrics). In high-stakes applications like teacher recommendations, higher recall (to minimize missed dropouts) or precision (to minimize unnecessary interventions) might be desired, depending on the relative costs of false negatives and false positives.\n",
            "\n",
            " Comparison with a Simple Baseline Model (Dummy Classifier)\n",
            "\n",
            "Performance of Baseline Dummy Classifier (Predicting Most Frequent Class):\n",
            "Accuracy: 0.5263\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n",
            "F1-score: 0.0000\n",
            "AUC: 0.5000\n",
            "\n",
            "Comparison Summary:\n",
            "Our Logistic Regression Model:\n",
            "Accuracy: 0.6842, Precision: 0.6667, Recall: 0.6667, F1-score: 0.6667, AUC: 0.8111\n",
            "\n",
            "Baseline Dummy Classifier:\n",
            "Accuracy: 0.5263, Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000, AUC: 0.5000\n",
            "\n",
            " Summary of Limited Comparative Assessment\n",
            "Due to the constraints of having only one dataset and no specific details about other methods from the articles, a comprehensive comparative assessment was not feasible.\n",
            "Comparing our Logistic Regression model's performance metrics (Accuracy: 0.6842, Precision: 0.6667, Recall: 0.6667, F1-score: 0.6667, AUC: 0.8111) against a simple Dummy Classifier that predicts the most frequent class (Accuracy: 0.5263, Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000, AUC: 0.5000) shows that our model offers a clear improvement.\n",
            "The Dummy Classifier's performance reflects the baseline accuracy achievable by simply guessing the majority class, and its other metrics are low or undefined.\n",
            "Our model's significantly higher AUC and balanced Precision/Recall/F1 scores indicate that it has learned meaningful patterns from the data and provides predictive value beyond this basic baseline.\n",
            "However, the inability to compare against methods specifically discussed in the articles means we cannot assess how our model performs relative to state-of-the-art or domain-specific approaches described in the literature.\n",
            "Future work would require access to the articles to understand and potentially implement the methods they propose for a more relevant and informative comparison.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "971eab3d"
      },
      "source": [
        "**Potential benefits**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63dd273c",
        "outputId": "7b9a0f9f-e64e-496d-9c37-f6b28a7ee7e2"
      },
      "source": [
        "print(\" Potential Benefits for Automatic Learning\")\n",
        "\n",
        "print(\"\\nBased on the analysis of the e-course data and the performance of the developed predictive model, there are several potential benefits of applying such methods for automatic learning:\")\n",
        "\n",
        "print(\"\\n1. Early Identification of At-Risk Students:\")\n",
        "print(\"   - The model, even with moderate performance, can serve as an initial filter to identify students who exhibit patterns of behavior in the e-course logs that are associated with dropout risk.\")\n",
        "print(\"   - This early identification is crucial because it allows for timely intervention before students become disengaged or fall too far behind.\")\n",
        "\n",
        "print(\"\\n2. Enabling Timely Interventions:\")\n",
        "print(\"   - By automatically flagging at-risk students, the system can trigger timely interventions, such as personalized messages from teachers, recommendations for additional resources, or proactive outreach.\")\n",
        "print(\"   - This is more efficient than manual review of all student activity and allows educators to focus their efforts on students who need it most.\")\n",
        "\n",
        "print(\"\\n3. Personalization of Learning Support:\")\n",
        "print(\"   - While not directly implemented in this basic model, the features used (e.g., log activity, tool usage, performance metrics) can be used in more sophisticated models to understand *why* a student is at risk.\")\n",
        "print(\"   - This understanding can inform personalized learning support strategies, tailoring recommendations or interventions to the specific needs and challenges of individual students.\")\n",
        "\n",
        "print(\"\\n4. Efficient Allocation of Teacher Resources:\")\n",
        "print(\"   - Teachers often have limited time and resources. A predictive system can help prioritize which students require immediate attention.\")\n",
        "print(\"   - By focusing on the students identified as high-risk, teachers can allocate their support and guidance more efficiently.\")\n",
        "\n",
        "print(\"\\n5. Providing Data-Driven Insights for Course Improvement:\")\n",
        "print(\"   - The features that are most influential in the predictive model can provide insights into which aspects of the e-course are associated with higher dropout risk.\")\n",
        "print(\"   - This data-driven feedback can inform course designers and instructors, helping them to identify problematic activities, tools, or content areas and make informed decisions for improving course design and pedagogy.\")\n",
        "\n",
        "print(\"\\nLimitations and Contingencies:\")\n",
        "print(\"It is important to acknowledge that the full realization of these benefits is contingent on improving the model's performance and addressing the trade-offs between precision and recall.\")\n",
        "print(\"- A higher recall would ensure fewer at-risk students are missed, which is critical for intervention systems.\")\n",
        "print(\"- Balancing this with acceptable precision is necessary to avoid overwhelming teachers with false alarms.\")\n",
        "print(\"Further model refinement, potentially using more advanced algorithms, additional data sources (if available), and careful tuning based on the specific costs of false positives and false negatives in this educational context, would be required to maximize the benefits for automatic learning.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Potential Benefits for Automatic Learning\n",
            "\n",
            "Based on the analysis of the e-course data and the performance of the developed predictive model, there are several potential benefits of applying such methods for automatic learning:\n",
            "\n",
            "1. Early Identification of At-Risk Students:\n",
            "   - The model, even with moderate performance, can serve as an initial filter to identify students who exhibit patterns of behavior in the e-course logs that are associated with dropout risk.\n",
            "   - This early identification is crucial because it allows for timely intervention before students become disengaged or fall too far behind.\n",
            "\n",
            "2. Enabling Timely Interventions:\n",
            "   - By automatically flagging at-risk students, the system can trigger timely interventions, such as personalized messages from teachers, recommendations for additional resources, or proactive outreach.\n",
            "   - This is more efficient than manual review of all student activity and allows educators to focus their efforts on students who need it most.\n",
            "\n",
            "3. Personalization of Learning Support:\n",
            "   - While not directly implemented in this basic model, the features used (e.g., log activity, tool usage, performance metrics) can be used in more sophisticated models to understand *why* a student is at risk.\n",
            "   - This understanding can inform personalized learning support strategies, tailoring recommendations or interventions to the specific needs and challenges of individual students.\n",
            "\n",
            "4. Efficient Allocation of Teacher Resources:\n",
            "   - Teachers often have limited time and resources. A predictive system can help prioritize which students require immediate attention.\n",
            "   - By focusing on the students identified as high-risk, teachers can allocate their support and guidance more efficiently.\n",
            "\n",
            "5. Providing Data-Driven Insights for Course Improvement:\n",
            "   - The features that are most influential in the predictive model can provide insights into which aspects of the e-course are associated with higher dropout risk.\n",
            "   - This data-driven feedback can inform course designers and instructors, helping them to identify problematic activities, tools, or content areas and make informed decisions for improving course design and pedagogy.\n",
            "\n",
            "Limitations and Contingencies:\n",
            "It is important to acknowledge that the full realization of these benefits is contingent on improving the model's performance and addressing the trade-offs between precision and recall.\n",
            "- A higher recall would ensure fewer at-risk students are missed, which is critical for intervention systems.\n",
            "- Balancing this with acceptable precision is necessary to avoid overwhelming teachers with false alarms.\n",
            "Further model refinement, potentially using more advanced algorithms, additional data sources (if available), and careful tuning based on the specific costs of false positives and false negatives in this educational context, would be required to maximize the benefits for automatic learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dddecfc8"
      },
      "source": [
        " **Explore other Machine Learning Models**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d342b526",
        "outputId": "26e3e93a-8365-4e2c-813e-b39a5ab2f88e"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression # Import Logistic Regression again\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Identify numerical and categorical features from the prepared training data X_train\n",
        "# This is important as the columns in X might differ based on successful feature engineering\n",
        "numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
        "# Filter categorical features to only include those present in X_train\n",
        "categorical_features = [col for col in X_train.select_dtypes(include='category').columns.tolist() if col in X_train.columns]\n",
        "\n",
        "\n",
        "# Create the preprocessor (consistent with previous steps but using features from X_train)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough' # Keep other columns (if any) - though in this case, all should be covered\n",
        ")\n",
        "\n",
        "# Define models to compare, including Logistic Regression\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42), # Added back LR for direct comparison\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"SVC\": SVC(probability=True, random_state=42) # probability=True to get AUC\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    print(f\"Training and evaluating {name}...\")\n",
        "\n",
        "    # Create pipeline\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('classifier', model)])\n",
        "\n",
        "    # Train the model\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    # Predict probabilities only if the model supports it (SVC needs probability=True)\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
        "        auc = roc_auc_score(y_test, y_prob)\n",
        "    else:\n",
        "        y_prob = None # Or handle differently if needed\n",
        "        auc = np.nan # AUC is not applicable without probabilities\n",
        "\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, zero_division=0) # Handle case with no positive predictions\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "    results[name] = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-score\": f1,\n",
        "        \"AUC\": auc\n",
        "    }\n",
        "    print(f\"{name} evaluation complete.\")\n",
        "\n",
        "print(\"\\n--- Model Comparison Results ---\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"  {metric}: {value:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating Logistic Regression...\n",
            "Logistic Regression evaluation complete.\n",
            "Training and evaluating Random Forest...\n",
            "Random Forest evaluation complete.\n",
            "Training and evaluating Gradient Boosting...\n",
            "Gradient Boosting evaluation complete.\n",
            "Training and evaluating SVC...\n",
            "SVC evaluation complete.\n",
            "\n",
            "--- Model Comparison Results ---\n",
            "\n",
            "Logistic Regression:\n",
            "  Accuracy: 0.6842\n",
            "  Precision: 0.6667\n",
            "  Recall: 0.6667\n",
            "  F1-score: 0.6667\n",
            "  AUC: 0.8111\n",
            "\n",
            "Random Forest:\n",
            "  Accuracy: 0.9474\n",
            "  Precision: 0.9000\n",
            "  Recall: 1.0000\n",
            "  F1-score: 0.9474\n",
            "  AUC: 0.9889\n",
            "\n",
            "Gradient Boosting:\n",
            "  Accuracy: 1.0000\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1-score: 1.0000\n",
            "  AUC: 1.0000\n",
            "\n",
            "SVC:\n",
            "  Accuracy: 0.7368\n",
            "  Precision: 0.8333\n",
            "  Recall: 0.5556\n",
            "  F1-score: 0.6667\n",
            "  AUC: 0.8222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbce02ca"
      },
      "source": [
        "**Comparing Machine Learning Models (Regenerated)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bcd445b",
        "outputId": "b3bea96e-913e-490c-e35a-c876e17d0a45"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the data\n",
        "try:\n",
        "    course_log_df = pd.read_excel(\"/content/data_EPX_2024_2025.xlsx\")\n",
        "    print(\"Data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: '/content/data_EPX_2024_2025.xlsx' not found. Please ensure the file is in the correct directory.\")\n",
        "    # Exit or handle the error appropriately if the file is essential\n",
        "    exit()\n",
        "\n",
        "# Preprocess data - Handling missing values\n",
        "# Impute with mode as a basic strategy for 'tool' and 'tool_performance'\n",
        "if 'tool' in course_log_df.columns:\n",
        "    tool_mode = course_log_df['tool'].mode()[0]\n",
        "    course_log_df['tool'].fillna(tool_mode, inplace=True)\n",
        "    print(\"Filled missing values in 'tool'.\")\n",
        "\n",
        "if 'tool_performance' in course_log_df.columns:\n",
        "    tool_performance_mode = course_log_df['tool_performance'].mode()[0]\n",
        "    course_log_df['tool_performance'].fillna(tool_performance_mode, inplace=True)\n",
        "    print(\"Filled missing values in 'tool_performance'.\")\n",
        "\n",
        "\n",
        "# Preprocess data - Converting data types\n",
        "# Convert 'activity' and 'level' to 'category' dtype if suitable\n",
        "if 'activity' in course_log_df.columns and course_log_df['activity'].nunique() < 500:\n",
        "    course_log_df['activity'] = course_log_df['activity'].astype('category')\n",
        "    print(\"Converted 'activity' to category.\")\n",
        "\n",
        "if 'level' in course_log_df.columns and course_log_df['level'].nunique() < 100:\n",
        "    course_log_df['level'] = course_log_df['level'].astype('category')\n",
        "    print(\"Converted 'level' to category.\")\n",
        "\n",
        "print(\"\\nData preprocessing complete.\")\n",
        "\n",
        "\n",
        "# Feature engineering (Regenerated based on previous steps)\n",
        "if 'tool_code' in course_log_df.columns and 'logs' in course_log_df.columns:\n",
        "    tool_log_counts = course_log_df.groupby('tool_code')['logs'].sum().reset_index(name='total_logs_per_tool')\n",
        "    course_log_df = pd.merge(course_log_df, tool_log_counts, on='tool_code', how='left')\n",
        "    print(\"Engineered 'total_logs_per_tool'.\")\n",
        "\n",
        "if 'level' in course_log_df.columns and 'log_weight' in course_log_df.columns:\n",
        "    level_avg_log_weight = course_log_df.groupby('level')['log_weight'].mean().reset_index(name='avg_log_weight_per_level')\n",
        "    course_log_df = pd.merge(course_log_df, level_avg_log_weight, on='level', how='left')\n",
        "    print(\"Engineered 'avg_log_weight_per_level'.\")\n",
        "\n",
        "if 'level' in course_log_df.columns and 'tool_performance' in course_log_df.columns:\n",
        "    level_avg_tool_performance = course_log_df.groupby('level')['tool_performance'].mean().reset_index(name='avg_tool_performance_per_level')\n",
        "    course_log_df = pd.merge(course_log_df, level_avg_tool_performance, on='level', how='left')\n",
        "    print(\"Engineered 'avg_tool_performance_per_level'.\")\n",
        "\n",
        "if 'tool_weight' in course_log_df.columns and 'log_weight' in course_log_df.columns:\n",
        "    course_log_df['tool_log_interaction'] = course_log_df['tool_weight'] * course_log_df['log_weight']\n",
        "    print(\"Engineered 'tool_log_interaction'.\")\n",
        "\n",
        "print(\"\\nFeature engineering complete.\")\n",
        "\n",
        "# Create synthetic target variable 'dropout' for demonstration purposes\n",
        "# Using the same method as before based on 'tool_log_interaction' median\n",
        "if 'tool_log_interaction' in course_log_df.columns:\n",
        "    threshold = course_log_df['tool_log_interaction'].median()\n",
        "    course_log_df['dropout'] = (course_log_df['tool_log_interaction'] < threshold).astype(int)\n",
        "    print(\"\\nCreated synthetic 'dropout' target variable.\")\n",
        "else:\n",
        "     # If 'tool_log_interaction' could not be engineered, create a simple dummy target\n",
        "     print(\"\\n'tool_log_interaction' not found. Creating a simple dummy 'dropout' target for demonstration.\")\n",
        "     course_log_df['dropout'] = np.random.randint(0, 2, size=len(course_log_df))\n",
        "\n",
        "\n",
        "# Define features (X) and target (y) for the entire dataset\n",
        "# Ensure all engineered features that exist are included, and handle potential missing columns gracefully\n",
        "available_features = [f for f in ['tool_code', 'tool', 'level_index', 'tool_weight', 'ECTS_weight', 'logs', 'log_weight', 'tool_performance', 'total_logs_per_tool', 'avg_log_weight_per_level', 'avg_tool_performance_per_level', 'tool_log_interaction'] if f in course_log_df.columns]\n",
        "\n",
        "X = course_log_df[available_features]\n",
        "y = course_log_df['dropout']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"\\nData split into training and testing sets.\")\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Filled missing values in 'tool'.\n",
            "Filled missing values in 'tool_performance'.\n",
            "Converted 'activity' to category.\n",
            "Converted 'level' to category.\n",
            "\n",
            "Data preprocessing complete.\n",
            "Engineered 'total_logs_per_tool'.\n",
            "Engineered 'avg_log_weight_per_level'.\n",
            "Engineered 'avg_tool_performance_per_level'.\n",
            "Engineered 'tool_log_interaction'.\n",
            "\n",
            "Feature engineering complete.\n",
            "\n",
            "Created synthetic 'dropout' target variable.\n",
            "\n",
            "Data split into training and testing sets.\n",
            "Shape of X_train: (76, 12)\n",
            "Shape of y_train: (76,)\n",
            "Shape of X_test: (19, 12)\n",
            "Shape of y_test: (19,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2727601681.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  course_log_df['tool'].fillna(tool_mode, inplace=True)\n",
            "/tmp/ipython-input-2727601681.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  course_log_df['tool_performance'].fillna(tool_performance_mode, inplace=True)\n",
            "/tmp/ipython-input-2727601681.py:50: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  level_avg_log_weight = course_log_df.groupby('level')['log_weight'].mean().reset_index(name='avg_log_weight_per_level')\n",
            "/tmp/ipython-input-2727601681.py:55: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  level_avg_tool_performance = course_log_df.groupby('level')['tool_performance'].mean().reset_index(name='avg_tool_performance_per_level')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88f5d6a6"
      },
      "source": [
        "Load and Preprocess Data (Regenerated)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cee0046",
        "outputId": "55d69486-b9ad-4d7a-9e2a-5d0be93234ba"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the data\n",
        "try:\n",
        "    course_log_df = pd.read_excel(\"/content/data_EPX_2024_2025.xlsx\")\n",
        "    print(\"Data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: '/content/data_EPX_2024_2025.xlsx' not found. Please ensure the file is in the correct directory.\")\n",
        "    # Exit or handle the error appropriately if the file is essential\n",
        "    exit()\n",
        "\n",
        "\n",
        "# Preprocess data - Handling missing values\n",
        "# Impute with mode as a basic strategy for 'tool' and 'tool_performance'\n",
        "if 'tool' in course_log_df.columns:\n",
        "    tool_mode = course_log_df['tool'].mode()[0]\n",
        "    course_log_df['tool'].fillna(tool_mode, inplace=True)\n",
        "    print(\"Filled missing values in 'tool'.\")\n",
        "\n",
        "if 'tool_performance' in course_log_df.columns:\n",
        "    tool_performance_mode = course_log_df['tool_performance'].mode()[0]\n",
        "    course_log_df['tool_performance'].fillna(tool_performance_mode, inplace=True)\n",
        "    print(\"Filled missing values in 'tool_performance'.\")\n",
        "\n",
        "\n",
        "# Preprocess data - Converting data types\n",
        "# Convert 'activity' and 'level' to 'category' dtype if suitable\n",
        "if 'activity' in course_log_df.columns and course_log_df['activity'].nunique() < 500:\n",
        "    course_log_df['activity'] = course_log_df['activity'].astype('category')\n",
        "    print(\"Converted 'activity' to category.\")\n",
        "\n",
        "if 'level' in course_log_df.columns and course_log_df['level'].nunique() < 100:\n",
        "    course_log_df['level'] = course_log_df['level'].astype('category')\n",
        "    print(\"Converted 'level' to category.\")\n",
        "\n",
        "print(\"\\nData preprocessing complete.\")\n",
        "\n",
        "\n",
        "# Feature engineering (Regenerated based on previous steps)\n",
        "if 'tool_code' in course_log_df.columns and 'logs' in course_log_df.columns:\n",
        "    tool_log_counts = course_log_df.groupby('tool_code')['logs'].sum().reset_index(name='total_logs_per_tool')\n",
        "    course_log_df = pd.merge(course_log_df, tool_log_counts, on='tool_code', how='left')\n",
        "    print(\"Engineered 'total_logs_per_tool'.\")\n",
        "\n",
        "if 'level' in course_log_df.columns and 'log_weight' in course_log_df.columns:\n",
        "    level_avg_log_weight = course_log_df.groupby('level')['log_weight'].mean().reset_index(name='avg_log_weight_per_level')\n",
        "    course_log_df = pd.merge(course_log_df, level_avg_log_weight, on='level', how='left')\n",
        "    print(\"Engineered 'avg_log_weight_per_level'.\")\n",
        "\n",
        "if 'level' in course_log_df.columns and 'tool_performance' in course_log_df.columns:\n",
        "    level_avg_tool_performance = course_log_df.groupby('level')['tool_performance'].mean().reset_index(name='avg_tool_performance_per_level')\n",
        "    course_log_df = pd.merge(course_log_df, level_avg_tool_performance, on='level', how='left')\n",
        "    print(\"Engineered 'avg_tool_performance_per_level'.\")\n",
        "\n",
        "if 'tool_weight' in course_log_df.columns and 'log_weight' in course_log_df.columns:\n",
        "    course_log_df['tool_log_interaction'] = course_log_df['tool_weight'] * course_log_df['log_weight']\n",
        "    print(\"Engineered 'tool_log_interaction'.\")\n",
        "\n",
        "print(\"\\nFeature engineering complete.\")\n",
        "\n",
        "# Create synthetic target variable 'dropout' for demonstration purposes\n",
        "# Using the same method as before based on 'tool_log_interaction' median\n",
        "if 'tool_log_interaction' in course_log_df.columns:\n",
        "    threshold = course_log_df['tool_log_interaction'].median()\n",
        "    course_log_df['dropout'] = (course_log_df['tool_log_interaction'] < threshold).astype(int)\n",
        "    print(\"\\nCreated synthetic 'dropout' target variable.\")\n",
        "else:\n",
        "     # If 'tool_log_interaction' could not be engineered, create a simple dummy target\n",
        "     print(\"\\n'tool_log_interaction' not found. Creating a simple dummy 'dropout' target for demonstration.\")\n",
        "     course_log_df['dropout'] = np.random.randint(0, 2, size=len(course_log_df))\n",
        "\n",
        "\n",
        "# Define features (X) and target (y) for the entire dataset\n",
        "# Ensure all engineered features that exist are included, and handle potential missing columns gracefully\n",
        "available_features = [f for f in ['tool_code', 'tool', 'level_index', 'tool_weight', 'ECTS_weight', 'logs', 'log_weight', 'tool_performance', 'total_logs_per_tool', 'avg_log_weight_per_level', 'avg_tool_performance_per_level', 'tool_log_interaction'] if f in course_log_df.columns]\n",
        "\n",
        "X = course_log_df[available_features]\n",
        "y = course_log_df['dropout']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"\\nData split into training and testing sets.\")\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Filled missing values in 'tool'.\n",
            "Filled missing values in 'tool_performance'.\n",
            "Converted 'activity' to category.\n",
            "Converted 'level' to category.\n",
            "\n",
            "Data preprocessing complete.\n",
            "Engineered 'total_logs_per_tool'.\n",
            "Engineered 'avg_log_weight_per_level'.\n",
            "Engineered 'avg_tool_performance_per_level'.\n",
            "Engineered 'tool_log_interaction'.\n",
            "\n",
            "Feature engineering complete.\n",
            "\n",
            "Created synthetic 'dropout' target variable.\n",
            "\n",
            "Data split into training and testing sets.\n",
            "Shape of X_train: (76, 12)\n",
            "Shape of y_train: (76,)\n",
            "Shape of X_test: (19, 12)\n",
            "Shape of y_test: (19,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-545394939.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  course_log_df['tool'].fillna(tool_mode, inplace=True)\n",
            "/tmp/ipython-input-545394939.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  course_log_df['tool_performance'].fillna(tool_performance_mode, inplace=True)\n",
            "/tmp/ipython-input-545394939.py:51: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  level_avg_log_weight = course_log_df.groupby('level')['log_weight'].mean().reset_index(name='avg_log_weight_per_level')\n",
            "/tmp/ipython-input-545394939.py:56: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  level_avg_tool_performance = course_log_df.groupby('level')['tool_performance'].mean().reset_index(name='avg_tool_performance_per_level')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f4741a4"
      },
      "source": [
        "Comparing Machine Learning Models (Regenerated)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5e8d4b6",
        "outputId": "98460de4-532f-49a9-d3ea-1ebd09282ca5"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression # Import Logistic Regression again\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Identify numerical and categorical features from the prepared training data X_train\n",
        "# This is important as the columns in X might differ based on successful feature engineering\n",
        "numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
        "# Filter categorical features to only include those present in X_train\n",
        "categorical_features = [col for col in X_train.select_dtypes(include='category').columns.tolist() if col in X_train.columns]\n",
        "\n",
        "\n",
        "# Create the preprocessor (consistent with previous steps but using features from X_train)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough' # Keep other columns (if any) - though in this case, all should be covered\n",
        ")\n",
        "\n",
        "# Define models to compare, including Logistic Regression\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42), # Added back LR for direct comparison\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"SVC\": SVC(probability=True, random_state=42) # probability=True to get AUC\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    print(f\"Training and evaluating {name}...\")\n",
        "\n",
        "    # Create pipeline\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('classifier', model)])\n",
        "\n",
        "    # Train the model\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    # Predict probabilities only if the model supports it (SVC needs probability=True)\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
        "        auc = roc_auc_score(y_test, y_prob)\n",
        "    else:\n",
        "        y_prob = None # Or handle differently if needed\n",
        "        auc = np.nan # AUC is not applicable without probabilities\n",
        "\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, zero_division=0) # Handle case with no positive predictions\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "    results[name] = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-score\": f1,\n",
        "        \"AUC\": auc\n",
        "    }\n",
        "    print(f\"{name} evaluation complete.\")\n",
        "\n",
        "print(\"\\n--- Model Comparison Results ---\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"  {metric}: {value:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating Logistic Regression...\n",
            "Logistic Regression evaluation complete.\n",
            "Training and evaluating Random Forest...\n",
            "Random Forest evaluation complete.\n",
            "Training and evaluating Gradient Boosting...\n",
            "Gradient Boosting evaluation complete.\n",
            "Training and evaluating SVC...\n",
            "SVC evaluation complete.\n",
            "\n",
            "--- Model Comparison Results ---\n",
            "\n",
            "Logistic Regression:\n",
            "  Accuracy: 0.6842\n",
            "  Precision: 0.6667\n",
            "  Recall: 0.6667\n",
            "  F1-score: 0.6667\n",
            "  AUC: 0.8111\n",
            "\n",
            "Random Forest:\n",
            "  Accuracy: 0.9474\n",
            "  Precision: 0.9000\n",
            "  Recall: 1.0000\n",
            "  F1-score: 0.9474\n",
            "  AUC: 0.9889\n",
            "\n",
            "Gradient Boosting:\n",
            "  Accuracy: 1.0000\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1-score: 1.0000\n",
            "  AUC: 1.0000\n",
            "\n",
            "SVC:\n",
            "  Accuracy: 0.7368\n",
            "  Precision: 0.8333\n",
            "  Recall: 0.5556\n",
            "  F1-score: 0.6667\n",
            "  AUC: 0.8222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "This analysis demonstrates the feasibility and potential of using machine learning on e-course data for predictive purposes, providing a strong foundation for future work with real dropout data."
      ],
      "metadata": {
        "id": "wRZnVJh2HkLx"
      }
    }
  ]
}